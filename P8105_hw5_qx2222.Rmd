---
title: "P8105_hw5_qx2222"
author: "Qiaoyi Xu"
date: "2022-11-15"
output: github_document
---


```{r}
library(tidyverse)
set.seed(1)
```

## Problem 1 (answer posted)

The code chunk below imports the data in individual spreadsheets contained in `./data/zip_data/`. To do this, I create a dataframe that includes the list of all files in that directory and the complete path to each file. As a next step, I `map` over paths and import data using the `read_csv` function. Finally, I `unnest` the result of `map`.

```{r, message=FALSE,warning=FALSE}
full_df = 
  tibble(
    files = list.files("data/problem1_data/"),
    path = str_c("data/problem1_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

The result of the previous code chunk isn't tidy -- data are wide rather than long, and some important variables are included as parts of others. The code chunk below tides the data using string manipulations on the file, converting from wide to long, and selecting relevant variables. 

```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Finally, the code chunk below creates a plot showing individual data, faceted by group. 

```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

This plot suggests high within-subject correlation -- subjects who start above average end up above average, and those that start below average end up below average. Subjects in the control group generally don't change over time, but those in the experiment group increase their outcome in a roughly linear way. 




## Problem 2

### Import homicide data
```{r}
homicide = read_csv("data/homicide-data.csv") #import 'homicide' data

homicide
```


### Describe the raw data:

In the raw homicide data, there are `r nrow(homicide)` observations and `r ncol(homicide)` variables. 


### Create new variables
```{r}
homicide = homicide %>%
  mutate(city_state = str_c(city, ", ", state)) %>%
  mutate(homicide_status = if_else(disposition == "Closed without arrest", "unsolved",
                                   if_else(disposition == "Open/No arrest", "unsolved",
                                           if_else(disposition == "Closed by arrest", "solved", NA_character_))))

homicide
```

###Summarized table
```{r}
homicide_table = homicide %>%
  group_by(city_state) %>%
  summarise(total_homicide = n(),
            number_unsolved = sum(homicide_status == "unsolved")) %>%
  knitr::kable(col.names = c("City, State", "Total number of homicide", "Number of unsolved homicide"))

homicide_table
```

### For the city of Baltimore, MD
```{r}
Balto = homicide %>%
  filter(city_state == "Baltimore, MD") %>%
  summarise(total_homicide = n(),
            number_unsolved = sum(homicide_status == "unsolved"))

Balto_prop <- 
  prop.test(Balto %>% pull(number_unsolved), Balto %>% pull(total_homicide))

Balto_prop %>% broom::tidy() %>%
  knitr::kable()
```

### For each of the cities
```{r}
proptest_function = function(df) {
  summary = df %>% 
    summarise(total_homicide = n(),
              number_unsolved = sum(homicide_status == "unsolved"))
              
  cities_proptest = prop.test(summary %>% pull(number_unsolved), 
                              summary %>% pull(total_homicide)) %>%
    broom::tidy()
  
  cities_proptest
}


cities_final = homicide %>%
  nest(data = -city_state) %>%
  mutate(cities_test = map(data, proptest_function)) %>%
  unnest(cities_test) %>%
  select(city_state,estimate,starts_with('conf'))

cities_final %>%
  knitr::kable(col.names = c("City, State", "estimate","confidenceinterval_low","confidenceinterval_high"))
  
```

### Create plot
```{r}
plot_cities = cities_final %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes (x = city_state, y = estimate)) +
  geom_point()+
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))+
  theme(axis.text.x = element_text(angle = 90))+
  labs(x = "City, State", y = "Estimates of unsolved homicide porpotion",
       title = "Estimates and 95% CIs for each city")

plot_cities #shows the estimates and 95% CIs for each city


ggsave(
  filename = "results/plot for each city.pdf",
  plot = plot_cities,
  width = 30,
  height = 20,
  units = "cm"
  ) #export plot to 'results' directory

```

## Problem 3

### First set the following design elements:
Fix n=30
Fix σ=5
Set μ=0. 

```{r}
#write t-test function
ttest_function = function(n = 30, sd = 5, mu = 0) {
  sample = rnorm(n = n, sd = sd, mean = mu)
  result = t.test(sample) %>%
  broom::tidy()%>%
  select(estimate, p.value)
  
  result
}


```

### Generate 5000 datasets from the model

```{r}
prob3_df = 
  expand.grid(mean = 0, iteration = 1:5000) %>%
  mutate(result = map(.x = mean, ~ttest_function(mu=.x))) %>%
  unnest(result) %>%
  knitr::kable()
  
```

### Repeat the above for μ={1,2,3,4,5,6}

```{r}
prob3_diffmean = 
  expand.grid(mean = 1:6, iteration = 1:5000) %>%
  mutate(result = map(.x = mean, ~ttest_function(mu=.x))) %>%
  unnest(result) %>%
  knitr::kable()
```

### Make a plot(true mean v.s. proportion of times the null was rejected)

```{r}

```








